{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import os\n",
    "import json\n",
    "import ember\n",
    "import csv\n",
    "\n",
    "\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Input, Dense, Dropout\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "datadir = './data/ember2017_1/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create vectorized features\n",
    "X_train_path = os.path.join(datadir, \"X_train.dat\")\n",
    "y_train_path = os.path.join(datadir, \"y_train.dat\")\n",
    "if not (os.path.exists(X_train_path) and os.path.exists(y_train_path)):\n",
    "    print(\"Creating vectorized features\")\n",
    "    ember.create_vectorized_features(datadir, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training: read vectorized features\")\n",
    "x_train, y_train = ember.read_vectorized_features(datadir, \"train\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"testing: read vectorized features\")\n",
    "x_test, y_test = ember.read_vectorized_features(datadir, \"test\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_rows = y_train != -1\n",
    "print(train_rows.size)\n",
    "print(train_rows[500000])\n",
    "\n",
    "#filter training data by calling x_train[train_rows] and y_train[train_rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "\n",
    "n_inputs = 2381\n",
    "\n",
    "print(\"Building neural network\")\n",
    "model = Sequential()\n",
    "model.add(Dense(70, input_shape=(n_inputs,), activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(70, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "print(\"Compiling neural network\")\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "checkpath = os.path.join(os.path.dirname(os.path.abspath('')), \"checkpoints\")\n",
    "os.makedirs(checkpath, exist_ok=True)\n",
    "checkpath = os.path.join(checkpath, 'model-epoch{epoch:03d}-acc{val_acc:03f}.h5')\n",
    "\n",
    "stopper = EarlyStopping(monitor = 'val_acc', min_delta=0.0001, patience = 5, mode = 'auto')\n",
    "\n",
    "saver = ModelCheckpoint(checkpath, save_best_only=True, verbose=1, monitor='val_loss', mode='min')\n",
    "\n",
    "print(\"Training neural network...\")\n",
    "# train the model\n",
    "#! error with validation_data shape..\n",
    "fitted_model = model.fit(x_train[train_rows], y_train[train_rows],\n",
    "          epochs=3,\n",
    "          verbose=2, \n",
    "          validation_data=(x_test, y_test)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = to_categorical(y_test)\n",
    "print(y_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBER model\n",
    "\n",
    "params = {\n",
    "        \"boosting\": \"gbdt\",\n",
    "        \"objective\": \"binary\",\n",
    "        \"num_iterations\": 1000,\n",
    "        \"learning_rate\": 0.05,\n",
    "        \"num_leaves\": 2048,\n",
    "        \"max_depth\": 15,\n",
    "        \"min_data_in_leaf\": 50,\n",
    "        \"feature_fraction\": 0.5\n",
    "}\n",
    "\n",
    "print(\"training lightGBM model\")\n",
    "lgbm_model = ember.train_model(datadir, params, 2)\n",
    "lgbm_model.save_model(os.path.join(datadir, \"model.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
